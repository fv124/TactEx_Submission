{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51a5fd2",
   "metadata": {},
   "source": [
    "# Step 1:  Import Libraries, Prepare Robot and Set-Up Camera\n",
    "\n",
    "- Xarm SDK reference: https://github.com/xArm-Developer/xArm-Python-SDK/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b3f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from xarm.wrapper import XArmAPI\n",
    "import cv2.aruco as aruco\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a82dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up camera\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.rgb8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e4d3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBOT_IP: 192.168.1.117, VERSION: v2.5.5, PROTOCOL: V1, DETAIL: 6,12,FX8501,AC8500,v2.5.5, TYPE1300: [1, 1]\n",
      "change protocol identifier to 3\n",
      "[SDK][ERROR][2025-07-15 17:06:05][base.py:380] - - API -> clean_warn -> code=1\n",
      "[motion_enable], xArm is not ready to move\n",
      "[set_state], xArm is ready to move\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare robot\n",
    "arm = XArmAPI('192.168.1.117')  # Replace with your robot's IP address\n",
    "arm.connect()\n",
    "arm.clean_warn()\n",
    "arm.clean_error()\n",
    "arm.motion_enable(enable=True)\n",
    "arm.set_mode(0)      # Position mode\n",
    "arm.set_state(0)     # Ready state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac9ae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beginning pose of robot (easy for mounting checkerboard)\n",
    "pose = [-50.810581, -450.742157, 210.200928, -90, 0, -90]\n",
    "arm.set_position(x = pose[0], y=pose[1], z=pose[2], roll=pose[3], pitch=pose[4], yaw=pose[5], speed=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74603d33",
   "metadata": {},
   "source": [
    "# Step 2: Attach Checkerboard to Robot\n",
    "\n",
    "- You can choose between a normal checkerboard and the ChArUco version, however we do stimulate to take the second option. In that case the camera can be moved closer to the scene as the ChArUco allows for only partial display which keeps the variety in poses high.\n",
    "- Checkerboards can be printed here: https://calib.io/pages/camera-calibration-pattern-generator?srsltid=AfmBOorLrMXPaB0gHMyK0HNOnLuCq6Y1MaLlo5pN0_-Bl8UeyUumNPad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5afb6",
   "metadata": {},
   "source": [
    "# Step 3: Define Checkerboard Pattern and Get Camera Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1040b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARUCO_CCW_CENTER', 'ARUCO_CW_TOP_LEFT_CORNER', 'ArucoDetector', 'Board', 'CORNER_REFINE_APRILTAG', 'CORNER_REFINE_CONTOUR', 'CORNER_REFINE_NONE', 'CORNER_REFINE_SUBPIX', 'CharucoBoard', 'CharucoDetector', 'CharucoParameters', 'DICT_4X4_100', 'DICT_4X4_1000', 'DICT_4X4_250', 'DICT_4X4_50', 'DICT_5X5_100', 'DICT_5X5_1000', 'DICT_5X5_250', 'DICT_5X5_50', 'DICT_6X6_100', 'DICT_6X6_1000', 'DICT_6X6_250', 'DICT_6X6_50', 'DICT_7X7_100', 'DICT_7X7_1000', 'DICT_7X7_250', 'DICT_7X7_50', 'DICT_APRILTAG_16H5', 'DICT_APRILTAG_16h5', 'DICT_APRILTAG_25H9', 'DICT_APRILTAG_25h9', 'DICT_APRILTAG_36H10', 'DICT_APRILTAG_36H11', 'DICT_APRILTAG_36h10', 'DICT_APRILTAG_36h11', 'DICT_ARUCO_MIP_36H12', 'DICT_ARUCO_MIP_36h12', 'DICT_ARUCO_ORIGINAL', 'DetectorParameters', 'Dictionary', 'Dictionary_getBitsFromByteList', 'Dictionary_getByteListFromBits', 'EstimateParameters', 'GridBoard', 'RefineParameters', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_native', 'calibrateCameraAruco', 'calibrateCameraArucoExtended', 'calibrateCameraCharuco', 'calibrateCameraCharucoExtended', 'detectCharucoDiamond', 'detectMarkers', 'drawCharucoDiamond', 'drawDetectedCornersCharuco', 'drawDetectedDiamonds', 'drawDetectedMarkers', 'drawPlanarBoard', 'estimatePoseBoard', 'estimatePoseCharucoBoard', 'estimatePoseSingleMarkers', 'extendDictionary', 'generateImageMarker', 'getBoardObjectAndImagePoints', 'getPredefinedDictionary', 'interpolateCornersCharuco', 'refineDetectedMarkers', 'testCharucoCornersCollinear']\n",
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "print(dir(cv2.aruco))\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a778667",
   "metadata": {},
   "outputs": [],
   "source": [
    "square_size = 0.025\n",
    "marker_size = 0.018\n",
    "dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "\n",
    "charuco_board = aruco.CharucoBoard(\n",
    "    (7,5),                # size as a tuple (squaresX, squaresY)\n",
    "    square_size,\n",
    "    marker_size,\n",
    "    dictionary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a621dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[608.46307373   0.         309.3677063 ]\n",
      " [  0.         606.87322998 213.83302307]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "profile = pipeline.start(config)\n",
    "\n",
    "intr = profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "camera_matrix = np.array([\n",
    "    [intr.fx,    0,      intr.ppx],\n",
    "    [0,       intr.fy,   intr.ppy],\n",
    "    [0,          0,      1]\n",
    "])\n",
    "\n",
    "print(camera_matrix)\n",
    "\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc6191",
   "metadata": {},
   "source": [
    "# Step 4: Predefine Functions\n",
    "- Reference for calibration and part of code beneath from OpenCV forum: https://forum.opencv.org/t/eye-to-hand-calibration/5690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7b24ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charuco_object_points(charuco_ids, board):\n",
    "    squares_x, squares_y = board.getChessboardSize()\n",
    "    square_length = board.getSquareLength()\n",
    "    \n",
    "    object_points = []\n",
    "    for idx in charuco_ids.flatten():\n",
    "        x = idx % (squares_x - 1)\n",
    "        y = idx // (squares_x - 1)\n",
    "        object_points.append([x * square_length, y * square_length, 0.0])\n",
    "        \n",
    "    return np.array(object_points, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b19b4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(show_image=True):\n",
    "\n",
    "    for i in range(30):  # warm-up\n",
    "        pipeline.wait_for_frames()\n",
    "        \n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)\n",
    "\n",
    "    # Main loop\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Save and convert to grayscale\n",
    "    cv2.imwrite('checkerboard_image.png', color_image)\n",
    "\n",
    "    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)  # Correct now\n",
    "\n",
    "    if show_image:\n",
    "        cv2.imshow(\"Checkerboard\", gray)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8cbfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_targetcam_charuco(gray, charuco_board, camera_matrix):\n",
    "    # 1. Detect markers\n",
    "    dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "    parameters = aruco.DetectorParameters()\n",
    "    corners, ids, rejected = aruco.detectMarkers(gray, dictionary, parameters=parameters)\n",
    "    dist_coeffs = np.zeros((5, 1))\n",
    "    \n",
    "    if ids is None or len(ids) == 0:\n",
    "        print(\"No markers detected\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 2. Interpolate Charuco corners\n",
    "    retval, charuco_corners, charuco_ids = aruco.interpolateCornersCharuco(corners, ids, gray, charuco_board)\n",
    "    if retval < 4:  # Need at least 4 corners to solve PnP\n",
    "        print(\"Not enough Charuco corners detected\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 3. Solve PnP with Charuco corners\n",
    "    object_points = get_charuco_object_points(charuco_ids, charuco_board)\n",
    "    success, rvec, tvec = cv2.solvePnP(object_points, charuco_corners, camera_matrix, dist_coeffs)\n",
    "    if not success:\n",
    "        print(\"solvePnP failed\")\n",
    "        return None, None, None\n",
    "\n",
    "    # 4. Convert rotation vector to matrix\n",
    "    R_target2cam, _ = cv2.Rodrigues(rvec)\n",
    "\n",
    "    # 5. Build homogeneous transformation matrix\n",
    "    H_target2cam = np.eye(4)\n",
    "    H_target2cam[:3, :3] = R_target2cam\n",
    "    H_target2cam[:3, 3] = tvec.squeeze()\n",
    "\n",
    "    return H_target2cam, R_target2cam, tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6c8b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler_to_matrix(rx, ry, rz, degrees=True):\n",
    "    \"\"\"\n",
    "    Convert Euler angles to a 3x3 rotation matrix.\n",
    "    Assumes XYZ order: roll (X), pitch (Y), yaw (Z).\n",
    "    \n",
    "    Set degrees=True if input is in degrees.\n",
    "    \"\"\"\n",
    "    r = R.from_euler('xyz', [rx, ry, rz], degrees=degrees)\n",
    "    return r.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74532101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pose limits\n",
    "x_range = [-320, 120]     # forward/back\n",
    "y_range = [-640, -280]  # left/right\n",
    "z_range = [185,290]     # height above table\n",
    "rx_range = [-80, -100]     # roll (degrees)\n",
    "ry_range = [-30, +30]     # pitch\n",
    "rz_range = [-60, -110]   # yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f141eb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_pose():\n",
    "    x = np.random.uniform(*x_range)\n",
    "    y = np.random.uniform(*y_range)\n",
    "    z = np.random.uniform(*z_range)\n",
    "    rx = np.random.uniform(*rx_range)\n",
    "    ry = np.random.uniform(*ry_range)\n",
    "    rz = np.random.uniform(*rz_range)\n",
    "    return [x, y, z, rx, ry, rz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "519216db",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_gripper2base_list = []\n",
    "t_gripper2base_list = []\n",
    "R_target2cam_list   = []\n",
    "t_target2cam_list   = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa814a",
   "metadata": {},
   "source": [
    "# Step 5: Collect between 20 and 40 calibration poses\n",
    "- The most important is to get a high variety of poses, set the camera as such that it is not too far from scene but still can see the checkerboard pattern.\n",
    "- In case of error during calibration you can just go rerun untill you reach your desired amount of poses\n",
    "- Set time.sleep to at least 6 to allow pose variations to take place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c262d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 1\n",
      "No markers detected\n",
      "Pose estimation failed at iteration 2\n",
      "No markers detected\n",
      "Pose estimation failed at iteration 7\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 9\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 11\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 17\n",
      "No markers detected\n",
      "Pose estimation failed at iteration 18\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 19\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 21\n",
      "No markers detected\n",
      "Pose estimation failed at iteration 26\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 27\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 31\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 32\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 33\n",
      "Not enough Charuco corners detected\n",
      "Pose estimation failed at iteration 36\n"
     ]
    }
   ],
   "source": [
    "pipeline.start(config)\n",
    "for i in range(40):\n",
    "    pose = generate_random_pose()\n",
    "    arm.set_position(x=pose[0], y=pose[1], z=pose[2], roll=pose[3], pitch=pose[4], yaw=pose[5], speed=60)\n",
    "    time.sleep(7)\n",
    "    \n",
    "    gray = get_image()\n",
    "    \n",
    "    # Use Charuco pose estimation\n",
    "    H1, R1, t1 = get_matrix_targetcam_charuco(gray, charuco_board, camera_matrix)\n",
    "    if H1 is None:\n",
    "        print(f\"Pose estimation failed at iteration {i}\")\n",
    "        continue\n",
    "    else:\n",
    "        R_target2cam_list.append(R1)\n",
    "        t_target2cam_list.append(t1)\n",
    "\n",
    "        x, y, z, rx, ry, rz = arm.get_position()[1]\n",
    "        R2 = euler_to_matrix(rx, ry, rz)\n",
    "        t2 = np.array([x, y, z]) / 1000  # assuming arm units are mm, convert to meters\n",
    "\n",
    "        R_gripper2base_list.append(R2)\n",
    "        t_gripper2base_list.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "275aafa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33ddded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(t_target2cam_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95705962",
   "metadata": {},
   "source": [
    "# Step 6: Calculate final matrix\n",
    "- - Reference for calibration and part of code beneath from OpenCV forum: https://forum.opencv.org/t/eye-to-hand-calibration/5690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "975b6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_eye_hand(R_gripper2base, t_gripper2base, R_target2cam, t_target2cam, eye_to_hand=True):\n",
    "\n",
    "    if eye_to_hand:\n",
    "        # change coordinates from gripper2base to base2gripper\n",
    "        R_base2gripper, t_base2gripper = [], []\n",
    "        for Rs, t in zip(R_gripper2base, t_gripper2base):\n",
    "            R_b2g = Rs.T\n",
    "            t_b2g = -R_b2g @ t\n",
    "            R_base2gripper.append(R_b2g)\n",
    "            t_base2gripper.append(t_b2g)\n",
    "        \n",
    "        # change parameters values\n",
    "        R_gripper2base = R_base2gripper\n",
    "        t_gripper2base = t_base2gripper\n",
    "\n",
    "    # calibrate\n",
    "    Rs, t = cv2.calibrateHandEye(\n",
    "        R_gripper2base=R_gripper2base,\n",
    "        t_gripper2base=t_gripper2base,\n",
    "        R_target2cam=R_target2cam,\n",
    "        t_target2cam=t_target2cam,\n",
    "    )\n",
    "\n",
    "    return Rs, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55fc45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_cam2gripper = np.zeros((3,3))\n",
    "t_cam2gripper = np.zeros((3,1))\n",
    "\n",
    "R_cam2gripper, t_cam2gripper = calibrate_eye_hand(\n",
    "    R_gripper2base_list,\n",
    "    t_gripper2base_list,\n",
    "    R_target2cam_list,\n",
    "    t_target2cam_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c29d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00931726  0.49773261 -0.86728048  0.42422236]\n",
      " [ 0.99949162  0.02181089  0.02325489 -0.54609013]\n",
      " [ 0.03049087 -0.86705625 -0.49727635  0.3433215 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[ 9.31725586e-03  4.97732608e-01 -8.67280485e-01  4.24222357e+02]\n",
      " [ 9.99491619e-01  2.18108861e-02  2.32548855e-02 -5.46090133e+02]\n",
      " [ 3.04908707e-02 -8.67056247e-01 -4.97276352e-01  3.43321500e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "H_cam2gripper = np.eye(4)\n",
    "H_cam2gripper[:3, :3] = R_cam2gripper\n",
    "H_cam2gripper[:3, 3] = t_cam2gripper.squeeze()\n",
    "\n",
    "print(H_cam2gripper)\n",
    "\n",
    "H_cam2base = H_cam2gripper\n",
    "H_cam2base[:3,3] *= 1000\n",
    "print(H_cam2base)\n",
    "np.savetxt('cam2base.txt', H_cam2base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e2735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef1eec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
