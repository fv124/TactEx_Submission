# TactEx_Project

<p align="center">
  <img src="https://github.com/user-attachments/assets/1f9b502d-818f-479b-9c1e-5a6c3b2c3a1c" width="600" height="350" alt="Overview Image">
</p>
This page contains the code to recreate the results reported from TactEx: A Multimodal Robotic Pipeline for Human-Like Touch and Hardness Estimation. The report can be consulted on this GitHub page as well (Main/Report_TactEx_Felix_Verstraete). This work was conducted at Imperial College London by members of the Embodied Intelligence Lab.

## Contents

- [Demo](#demo)
- [Calibration](#calibration)
- [Launching the interface](#Launchingtheinterface)
- [Tactile Perception Models](#Tactility)
- [Visual Servoing](#results)
- [NLP and LLM](#Language)

## Demo
https://github.com/user-attachments/assets/724e007f-3ee0-4272-ac70-260be6d979df

## Calibration
Before Launching the app, the user should calibrate the camera to the robot space. This takes about 5 minutes and is explained the notebook [notebook](./Calibration/Ca.pdf)

